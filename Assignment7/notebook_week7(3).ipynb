{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHoSDyYpdh-s"
   },
   "source": [
    "Assignment 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "02ZYZ-WmdhwH"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 7 by Josefin Kokkinakis and Eli Uhlin, group 30\n",
    "We have both worked around 20 hours each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJRCoRmew8Zd",
    "outputId": "8a74f963-06c8-4ba7-fb03-889e43dfa15e"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128 #specifies the number of samples used in each training iteration.\n",
    "num_classes = 10 # The amount of neurons in the output layer, each corresponding to a specific class. [0,...,9]\n",
    "epochs = 10 # The number of times the entire training data set is used during training.\n",
    "\n",
    "img_rows, img_cols = 28, 28 # image dimensions.\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n",
    "#Makes sure that the input data is shaped in a way that works with the Keras framework.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1: See comments in the block below for explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I3g1RrZ0wpI"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "UswCCQLS0s1I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#pixelvalues are normalized to the range 0 to 1\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#one-hot encoding, so \n",
    "#the training and test labels (categorical data variables)\n",
    "#are converted to a binary matrix that can be fed to the machine learning algo\n",
    "# for example [0,1,2,3] = [[1,0,0,0],\n",
    "#                          [0,1,0,0]\n",
    "#                          [0,0,1,0]\n",
    "#                          [0,0,0,1]]\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)\n",
    "\n",
    "\n",
    "len(x_train) # = 60 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "N7Aer42gk1W9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.8619 - val_loss: 0.2751 - val_accuracy: 0.9212\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2368 - accuracy: 0.9305 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.9468 - val_loss: 0.1627 - val_accuracy: 0.9523\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9570 - val_loss: 0.1468 - val_accuracy: 0.9535\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1256 - accuracy: 0.9633 - val_loss: 0.1691 - val_accuracy: 0.9451\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9671 - val_loss: 0.1148 - val_accuracy: 0.9659\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9720 - val_loss: 0.1051 - val_accuracy: 0.9678\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9742 - val_loss: 0.1181 - val_accuracy: 0.9629\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0776 - accuracy: 0.9770 - val_loss: 0.1000 - val_accuracy: 0.9700\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0700 - accuracy: 0.9792 - val_loss: 0.0952 - val_accuracy: 0.9698\n",
      "Test loss: 0.09516125917434692, Test accuracy 0.9697999954223633\n"
     ]
    }
   ],
   "source": [
    "## Define model ##\n",
    "model = Sequential() #allows us to build NN by stacking layers on top of each other\n",
    "\n",
    "#converts 2D input to a 1D vector\n",
    "model.add(Flatten())\n",
    "\n",
    "#relu introduces the non-linearity property to the model\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "#softmax to get probability dist over the classes (e.g. 0 to 9)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1), metrics=['accuracy'],)\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Network model, training, and changing hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_59 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. How many layers does the network in the notebook have? How many neurons does each layer have? \n",
    "What activation functions and why are these appropriate for this application? What is the total number of parameters for the network? \n",
    "Why do the input and output layers have the dimensions they have?\n",
    "\n",
    "Answer:\n",
    "1. Input layer: 28x28=784 input neurons. Flattening layer that converts matrix input to a vector\n",
    "2. Dense layer, consists of 64 neurons\n",
    "3. Dense layer, consists of 64 neurons\n",
    "4. Output layer: 10 sigmoid neurons (representing the numbers 0 to 9)\n",
    "\n",
    "There are two different activation functions here, relu and softmax.\n",
    "The relu (rectified linear unit) function introduces non-linearity to the output of the previous layer. It does this by setting the negative values to 0 (whilst not changing the positive ones). Relu is easier to compute than that the sigmoid function and it greatly speeds up training. Another positive aspect of relu is that it dosen't saturate it's neurons as badly as the Sigmoid function - Sigmoid has to squish an infinite range into a finite range $[0,1]$, this makes the partial derivative with respect to a certain weight very small, leading to minimal changes in weight connected to the neuron during backpropagation. This in term leads worse results and slower convergence.\n",
    "\n",
    "$$Relu(x) = max(0,x)$$\n",
    "\n",
    "Softmax activation function is used to get probability distributions over the classes. It uses the output of the previous layer and transforms it into a probability distribution (and at the same time ensuring that the probabilities add up to 1). It is important here because it lets us compare the predicted probabilities from the different numbers (classes).\n",
    "\n",
    "$$Softmax(X) = \\frac{exp(x_j)}{\\sum{i=1}{n}exp(x_i)} for j = 1,...,n $$ \n",
    "\n",
    "The total number of parameters is 55 050 (which we can see in the output of the cell above).\n",
    "For the input layer every neuron represents a pixel in the input image, every image consists of 784 pixels, hense 784 input neurons.\n",
    "Every neuron of the output layer represents a single class. we have 10 classes (binary digits from 0 to 9) hense we get 10 neurons.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. What loss function is used to train the network? What is the functional form (a mathematical expression) of the loss function? and how should we interpret it? Why is it appropriate for the problem at hand?\n",
    "\n",
    "The loss function is the categorical_crossentropy. It is appropriate since we are dealing with multiple classes. It based around using one-hot category encoding value in form of 0s and 1 to the output label.\n",
    "\n",
    "$$L_{CE}(s_1) = {-}\\sum_{i=1}^{n} T_i Log(S_i)$$ \n",
    "\n",
    "$S$ is a vector with the actual output values. $T$ is a vector with corresponding expected value or true value. For our case only one value in the vector $T$ will be equal to 1 and the rest is 0. \n",
    "This means that categorical crossentropy only depends on $S_i$ if  $T_i = 1$. as $S_i$ approaches 1, the value of $L_{CE}$ will go to zero, and as the value of $S_i$ approaches 0 $L_{CE}$ goes to infinity\n",
    "\n",
    "Categorical crossentropy is good for our model since we want our model to choose between 10 different classes, and the categorical crossentropy function works for an arbitrary number of classes, as opposed to the binary crossentropy function which can only put things into two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Train the network for 10 epochs and plot the training and validation accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4822 - accuracy: 0.8632 - val_loss: 0.2476 - val_accuracy: 0.9293\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2320 - accuracy: 0.9322 - val_loss: 0.1998 - val_accuracy: 0.9401\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.9471 - val_loss: 0.1838 - val_accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9570 - val_loss: 0.1554 - val_accuracy: 0.9526\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1266 - accuracy: 0.9636 - val_loss: 0.1306 - val_accuracy: 0.9601\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1099 - accuracy: 0.9676 - val_loss: 0.1274 - val_accuracy: 0.9615\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9713 - val_loss: 0.1027 - val_accuracy: 0.9693\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9748 - val_loss: 0.1066 - val_accuracy: 0.9683\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9773 - val_loss: 0.0958 - val_accuracy: 0.9713\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9790 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Test loss: 0.09567578136920929, Test accuracy 0.9708999991416931\n"
     ]
    }
   ],
   "source": [
    "## Define model ##\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model_2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1), metrics=['accuracy'],)\n",
    "fit_info = model_2.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy= fit_info.history['accuracy']\n",
    "label_1='training accuracy'\n",
    "label_2='validation accuracy'\n",
    "val_accuracy= fit_info.history['val_accuracy']\n",
    "x_epoch=list(range(1,11))\n",
    "plt.plot(x_epoch, train_accuracy, 'm', label = label_1, linewidth=3, alpha=0.3)\n",
    "plt.plot(x_epoch, val_accuracy, 'c', label = label_2, linewidth=3, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.title('Training and validation accuracy for the 10 epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. Update the model to implement a three-layer neural network where the hidden layers have 500 and 300 hidden units respectively. Train for 40 epochs. What is the best validation accuracy you can achieve?  Geoff Hinton (a co-pioneer of Deep learning) claimed this network could reach a validation accuracy of 0.9847 (http://yann.lecun.com/exdb/mnist/) using weight decay (L2 regularization of weights 2 (kernels): https://keras.io/api/layers/regularizers/). Implement weight decay on hidden units and train and select 5 regularization factors from 0.000001 to 0.001. Train 3 replicates networks for each regularization factor. Plot the final validation accuracy with standard deviation (computed from the replicates) as a function of the regularization factor. How close do you get to Hintons result?  If you do not get the same results, what factors may influence this? (hint: What information is not given by Hinton on the MNIST database that may influence Model training)\n",
    "\n",
    "Answer: It is possible that amount of epochs is what gives us a result lower than Geoff Hintons since we do not know how many epochs he had. We also don't know the regularization factors between 0.000001 and 0.001 were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1686 - accuracy: 0.8394 - val_loss: 0.8594 - val_accuracy: 0.9222\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7527 - accuracy: 0.9396 - val_loss: 0.6808 - val_accuracy: 0.9488\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6316 - accuracy: 0.9534 - val_loss: 0.5751 - val_accuracy: 0.9581\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5401 - accuracy: 0.9625 - val_loss: 0.5462 - val_accuracy: 0.9487\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4705 - accuracy: 0.9671 - val_loss: 0.4588 - val_accuracy: 0.9602\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4148 - accuracy: 0.9701 - val_loss: 0.4043 - val_accuracy: 0.9661\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3686 - accuracy: 0.9728 - val_loss: 0.3813 - val_accuracy: 0.9622\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3315 - accuracy: 0.9745 - val_loss: 0.3307 - val_accuracy: 0.9691\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3020 - accuracy: 0.9761 - val_loss: 0.2988 - val_accuracy: 0.9720\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2753 - accuracy: 0.9767 - val_loss: 0.2850 - val_accuracy: 0.9704\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2514 - accuracy: 0.9784 - val_loss: 0.2567 - val_accuracy: 0.9739\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2343 - accuracy: 0.9794 - val_loss: 0.2434 - val_accuracy: 0.9736\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2208 - accuracy: 0.9800 - val_loss: 0.2315 - val_accuracy: 0.9728\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2053 - accuracy: 0.9811 - val_loss: 0.2302 - val_accuracy: 0.9704\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1935 - accuracy: 0.9820 - val_loss: 0.2155 - val_accuracy: 0.9737\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1906 - accuracy: 0.9814 - val_loss: 0.2186 - val_accuracy: 0.9679\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1774 - accuracy: 0.9830 - val_loss: 0.1941 - val_accuracy: 0.9763\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1711 - accuracy: 0.9831 - val_loss: 0.1899 - val_accuracy: 0.9770\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1668 - accuracy: 0.9833 - val_loss: 0.1861 - val_accuracy: 0.9771\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9847 - val_loss: 0.1792 - val_accuracy: 0.9774\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1543 - accuracy: 0.9850 - val_loss: 0.1766 - val_accuracy: 0.9760\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1503 - accuracy: 0.9853 - val_loss: 0.1856 - val_accuracy: 0.9730\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1849 - accuracy: 0.9773 - val_loss: 0.1744 - val_accuracy: 0.9773\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1452 - accuracy: 0.9859 - val_loss: 0.2757 - val_accuracy: 0.9394\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9848 - val_loss: 0.2000 - val_accuracy: 0.9667\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1432 - accuracy: 0.9857 - val_loss: 0.1735 - val_accuracy: 0.9763\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9872 - val_loss: 0.1734 - val_accuracy: 0.9762\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1365 - accuracy: 0.9864 - val_loss: 0.1691 - val_accuracy: 0.9748\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1334 - accuracy: 0.9874 - val_loss: 0.1681 - val_accuracy: 0.9751\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1322 - accuracy: 0.9875 - val_loss: 0.1557 - val_accuracy: 0.9793\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1324 - accuracy: 0.9868 - val_loss: 0.1675 - val_accuracy: 0.9747\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1741 - accuracy: 0.9778 - val_loss: 0.1702 - val_accuracy: 0.9758\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1342 - accuracy: 0.9863 - val_loss: 0.1540 - val_accuracy: 0.9795\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9867 - val_loss: 0.1576 - val_accuracy: 0.9780\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1515 - accuracy: 0.9832 - val_loss: 0.1626 - val_accuracy: 0.9760\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9879 - val_loss: 0.1603 - val_accuracy: 0.9773\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1248 - accuracy: 0.9886 - val_loss: 0.1801 - val_accuracy: 0.9697\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1309 - accuracy: 0.9873 - val_loss: 0.1505 - val_accuracy: 0.9799\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1216 - accuracy: 0.9893 - val_loss: 0.1544 - val_accuracy: 0.9776\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1564 - accuracy: 0.9811 - val_loss: 0.1723 - val_accuracy: 0.9740\n",
      "Test loss: 0.17234812676906586, Test accuracy 0.9739999771118164\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2071 - accuracy: 0.8260 - val_loss: 0.8539 - val_accuracy: 0.9216\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7665 - accuracy: 0.9360 - val_loss: 0.6959 - val_accuracy: 0.9467\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6380 - accuracy: 0.9518 - val_loss: 0.6201 - val_accuracy: 0.9471\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5480 - accuracy: 0.9593 - val_loss: 0.5200 - val_accuracy: 0.9596\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4770 - accuracy: 0.9645 - val_loss: 0.4592 - val_accuracy: 0.9642\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4188 - accuracy: 0.9688 - val_loss: 0.4034 - val_accuracy: 0.9670\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3710 - accuracy: 0.9722 - val_loss: 0.3681 - val_accuracy: 0.9669\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3354 - accuracy: 0.9738 - val_loss: 0.3327 - val_accuracy: 0.9686\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3065 - accuracy: 0.9743 - val_loss: 0.3126 - val_accuracy: 0.9678\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.9770 - val_loss: 0.2785 - val_accuracy: 0.9724\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2544 - accuracy: 0.9780 - val_loss: 0.2568 - val_accuracy: 0.9728\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2345 - accuracy: 0.9798 - val_loss: 0.2469 - val_accuracy: 0.9721\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2191 - accuracy: 0.9811 - val_loss: 0.2295 - val_accuracy: 0.9752\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2228 - accuracy: 0.9768 - val_loss: 0.2374 - val_accuracy: 0.9689\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1974 - accuracy: 0.9816 - val_loss: 0.2216 - val_accuracy: 0.9711\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1846 - accuracy: 0.9829 - val_loss: 0.2006 - val_accuracy: 0.9752\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1771 - accuracy: 0.9830 - val_loss: 0.2012 - val_accuracy: 0.9734\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1721 - accuracy: 0.9827 - val_loss: 0.1915 - val_accuracy: 0.9753\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1635 - accuracy: 0.9841 - val_loss: 0.1803 - val_accuracy: 0.9769\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1781 - accuracy: 0.9805 - val_loss: 0.1847 - val_accuracy: 0.9760\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9835 - val_loss: 0.1763 - val_accuracy: 0.9759\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1512 - accuracy: 0.9851 - val_loss: 0.1740 - val_accuracy: 0.9760\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1468 - accuracy: 0.9859 - val_loss: 0.1692 - val_accuracy: 0.9772\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1449 - accuracy: 0.9857 - val_loss: 0.1872 - val_accuracy: 0.9732\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1530 - accuracy: 0.9829 - val_loss: 0.1623 - val_accuracy: 0.9782\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1419 - accuracy: 0.9858 - val_loss: 0.1822 - val_accuracy: 0.9707\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1357 - accuracy: 0.9877 - val_loss: 0.1601 - val_accuracy: 0.9776\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1344 - accuracy: 0.9871 - val_loss: 0.1599 - val_accuracy: 0.9779\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9866 - val_loss: 0.1696 - val_accuracy: 0.9745\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1785 - accuracy: 0.9765 - val_loss: 0.1614 - val_accuracy: 0.9778\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1348 - accuracy: 0.9862 - val_loss: 0.1589 - val_accuracy: 0.9778\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1307 - accuracy: 0.9873 - val_loss: 0.1593 - val_accuracy: 0.9775\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1602 - accuracy: 0.9803 - val_loss: 0.1610 - val_accuracy: 0.9781\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1279 - accuracy: 0.9882 - val_loss: 0.1545 - val_accuracy: 0.9776\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1263 - accuracy: 0.9884 - val_loss: 0.1467 - val_accuracy: 0.9811\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1269 - accuracy: 0.9876 - val_loss: 0.1563 - val_accuracy: 0.9779\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1233 - accuracy: 0.9890 - val_loss: 0.1494 - val_accuracy: 0.9787\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2108 - accuracy: 0.9707 - val_loss: 0.2110 - val_accuracy: 0.9667\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1556 - accuracy: 0.9800 - val_loss: 0.1650 - val_accuracy: 0.9775\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1359 - accuracy: 0.9858 - val_loss: 0.1665 - val_accuracy: 0.9762\n",
      "Test loss: 0.16648536920547485, Test accuracy 0.9761999845504761\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1815 - accuracy: 0.8332 - val_loss: 0.8389 - val_accuracy: 0.9227\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7499 - accuracy: 0.9414 - val_loss: 0.6807 - val_accuracy: 0.9486\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6245 - accuracy: 0.9560 - val_loss: 0.5848 - val_accuracy: 0.9572\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5369 - accuracy: 0.9625 - val_loss: 0.5051 - val_accuracy: 0.9608\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4685 - accuracy: 0.9671 - val_loss: 0.4523 - val_accuracy: 0.9620\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4131 - accuracy: 0.9708 - val_loss: 0.3956 - val_accuracy: 0.9681\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3668 - accuracy: 0.9730 - val_loss: 0.3578 - val_accuracy: 0.9690\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3284 - accuracy: 0.9752 - val_loss: 0.3195 - val_accuracy: 0.9716\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2972 - accuracy: 0.9768 - val_loss: 0.3533 - val_accuracy: 0.9512\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2710 - accuracy: 0.9789 - val_loss: 0.2790 - val_accuracy: 0.9710\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2523 - accuracy: 0.9785 - val_loss: 0.2584 - val_accuracy: 0.9726\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2311 - accuracy: 0.9803 - val_loss: 0.2386 - val_accuracy: 0.9757\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2158 - accuracy: 0.9814 - val_loss: 0.2683 - val_accuracy: 0.9596\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2026 - accuracy: 0.9817 - val_loss: 0.2371 - val_accuracy: 0.9680\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1914 - accuracy: 0.9825 - val_loss: 0.2070 - val_accuracy: 0.9757\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1832 - accuracy: 0.9830 - val_loss: 0.1996 - val_accuracy: 0.9762\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1778 - accuracy: 0.9825 - val_loss: 0.2366 - val_accuracy: 0.9607\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1699 - accuracy: 0.9833 - val_loss: 0.2038 - val_accuracy: 0.9718\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1629 - accuracy: 0.9843 - val_loss: 0.1855 - val_accuracy: 0.9763\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1661 - accuracy: 0.9823 - val_loss: 0.1867 - val_accuracy: 0.9752\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1524 - accuracy: 0.9859 - val_loss: 0.1809 - val_accuracy: 0.9749\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1490 - accuracy: 0.9858 - val_loss: 0.1799 - val_accuracy: 0.9756\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9859 - val_loss: 0.1735 - val_accuracy: 0.9745\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1426 - accuracy: 0.9868 - val_loss: 0.1709 - val_accuracy: 0.9756\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1635 - accuracy: 0.9804 - val_loss: 0.1784 - val_accuracy: 0.9752\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1916 - accuracy: 0.9751 - val_loss: 0.2000 - val_accuracy: 0.9698\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1530 - accuracy: 0.9829 - val_loss: 0.1819 - val_accuracy: 0.9741\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1399 - accuracy: 0.9860 - val_loss: 0.1686 - val_accuracy: 0.9758\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9868 - val_loss: 0.1659 - val_accuracy: 0.9757\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1348 - accuracy: 0.9873 - val_loss: 0.1686 - val_accuracy: 0.9734\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1338 - accuracy: 0.9865 - val_loss: 0.1586 - val_accuracy: 0.9795\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1885 - accuracy: 0.9752 - val_loss: 0.1770 - val_accuracy: 0.9725\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1373 - accuracy: 0.9857 - val_loss: 0.1688 - val_accuracy: 0.9745\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9869 - val_loss: 0.1824 - val_accuracy: 0.9691\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1428 - accuracy: 0.9847 - val_loss: 0.1659 - val_accuracy: 0.9772\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1262 - accuracy: 0.9887 - val_loss: 0.1918 - val_accuracy: 0.9662\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1279 - accuracy: 0.9874 - val_loss: 0.2178 - val_accuracy: 0.9560\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1254 - accuracy: 0.9877 - val_loss: 0.1670 - val_accuracy: 0.9744\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1230 - accuracy: 0.9886 - val_loss: 0.1575 - val_accuracy: 0.9771\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1474 - accuracy: 0.9816 - val_loss: 0.1556 - val_accuracy: 0.9785\n",
      "Test loss: 0.1555834412574768, Test accuracy 0.9785000085830688\n",
      "mean =  0.9762333234151205\n",
      "std =  0.0018372814011445343\n"
     ]
    }
   ],
   "source": [
    "## Define model ##\n",
    "regularization_factors=[0.001,0.0001,0.0005,0.00001,0.000001]\n",
    "val_acc_0_001=[]\n",
    "val_acc_0_0001=[]\n",
    "val_acc_0_0005=[]\n",
    "val_acc_0_00001=[]\n",
    "val_acc_0_000001=[]\n",
    "\n",
    "#regularization factor 0.001\n",
    "for _ in range(3):\n",
    "    model_3 = Sequential()\n",
    "    model_3.add(Flatten())\n",
    "    model_3.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model_3.add(Dense(64, activation = 'relu',kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model_3.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model_3.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L2(0.001)))\n",
    "\n",
    "    model_3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_3.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1), metrics=['accuracy'],)\n",
    "    epochs = 40\n",
    "    fit_info = model_3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "    val_acc_0_001.append(fit_info.history['val_accuracy'][-1])\n",
    "\n",
    "mean_0_001= np.mean(val_acc_0_001)\n",
    "std_0_001=np.std(val_acc_0_001)\n",
    "print('mean = ', mean_0_001)\n",
    "print('std = ', std_0_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6076 - accuracy: 0.8338 - val_loss: 0.3136 - val_accuracy: 0.9254\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2731 - accuracy: 0.9384 - val_loss: 0.2300 - val_accuracy: 0.9491\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2178 - accuracy: 0.9552 - val_loss: 0.2074 - val_accuracy: 0.9561\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1877 - accuracy: 0.9642 - val_loss: 0.1874 - val_accuracy: 0.9633\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1685 - accuracy: 0.9700 - val_loss: 0.1677 - val_accuracy: 0.9697\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1549 - accuracy: 0.9744 - val_loss: 0.2233 - val_accuracy: 0.9531\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1452 - accuracy: 0.9773 - val_loss: 0.1692 - val_accuracy: 0.9689\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1341 - accuracy: 0.9797 - val_loss: 0.1510 - val_accuracy: 0.9740\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9819 - val_loss: 0.1613 - val_accuracy: 0.9714\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1217 - accuracy: 0.9832 - val_loss: 0.2258 - val_accuracy: 0.9531\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1164 - accuracy: 0.9846 - val_loss: 0.1913 - val_accuracy: 0.9630\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1111 - accuracy: 0.9868 - val_loss: 0.1452 - val_accuracy: 0.9749\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1070 - accuracy: 0.9875 - val_loss: 0.1510 - val_accuracy: 0.9738\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9888 - val_loss: 0.1506 - val_accuracy: 0.9742\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0980 - accuracy: 0.9902 - val_loss: 0.1454 - val_accuracy: 0.9768\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9904 - val_loss: 0.1455 - val_accuracy: 0.9761\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0918 - accuracy: 0.9916 - val_loss: 0.1453 - val_accuracy: 0.9762\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9923 - val_loss: 0.1557 - val_accuracy: 0.9730\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9931 - val_loss: 0.1463 - val_accuracy: 0.9762\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9941 - val_loss: 0.1522 - val_accuracy: 0.9735\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9947 - val_loss: 0.1430 - val_accuracy: 0.9775\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9947 - val_loss: 0.1483 - val_accuracy: 0.9765\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.9952 - val_loss: 0.1429 - val_accuracy: 0.9782\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9963 - val_loss: 0.1429 - val_accuracy: 0.9775\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9965 - val_loss: 0.1540 - val_accuracy: 0.9750\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9963 - val_loss: 0.1453 - val_accuracy: 0.9761\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.9959 - val_loss: 0.1393 - val_accuracy: 0.9778\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0688 - accuracy: 0.9974 - val_loss: 0.1742 - val_accuracy: 0.9696\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9977 - val_loss: 0.1405 - val_accuracy: 0.9778\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.9976 - val_loss: 0.1590 - val_accuracy: 0.9740\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.9972 - val_loss: 0.1423 - val_accuracy: 0.9779\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9984 - val_loss: 0.1462 - val_accuracy: 0.9765\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0629 - accuracy: 0.9985 - val_loss: 0.1402 - val_accuracy: 0.9791\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0620 - accuracy: 0.9986 - val_loss: 0.1476 - val_accuracy: 0.9774\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9973 - val_loss: 0.1670 - val_accuracy: 0.9727\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0621 - accuracy: 0.9981 - val_loss: 0.1394 - val_accuracy: 0.9794\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9994 - val_loss: 0.1410 - val_accuracy: 0.9781\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.9998 - val_loss: 0.1449 - val_accuracy: 0.9767\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9998 - val_loss: 0.1385 - val_accuracy: 0.9792\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9999 - val_loss: 0.1332 - val_accuracy: 0.9802\n",
      "Test loss: 0.1331866979598999, Test accuracy 0.9801999926567078\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6298 - accuracy: 0.8310 - val_loss: 0.2937 - val_accuracy: 0.9297\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2655 - accuracy: 0.9403 - val_loss: 0.2456 - val_accuracy: 0.9480\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2122 - accuracy: 0.9561 - val_loss: 0.2051 - val_accuracy: 0.9577\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1844 - accuracy: 0.9649 - val_loss: 0.1968 - val_accuracy: 0.9585\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1653 - accuracy: 0.9714 - val_loss: 0.1707 - val_accuracy: 0.9693\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1509 - accuracy: 0.9747 - val_loss: 0.1609 - val_accuracy: 0.9720\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1402 - accuracy: 0.9779 - val_loss: 0.1561 - val_accuracy: 0.9737\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1328 - accuracy: 0.9801 - val_loss: 0.1566 - val_accuracy: 0.9728\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1258 - accuracy: 0.9820 - val_loss: 0.1473 - val_accuracy: 0.9753\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1180 - accuracy: 0.9847 - val_loss: 0.1715 - val_accuracy: 0.9674\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1119 - accuracy: 0.9863 - val_loss: 0.1492 - val_accuracy: 0.9746\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1084 - accuracy: 0.9869 - val_loss: 0.1522 - val_accuracy: 0.9738\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1035 - accuracy: 0.9878 - val_loss: 0.1553 - val_accuracy: 0.9751\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1007 - accuracy: 0.9893 - val_loss: 0.1465 - val_accuracy: 0.9770\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0972 - accuracy: 0.9898 - val_loss: 0.1412 - val_accuracy: 0.9784\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0954 - accuracy: 0.9905 - val_loss: 0.1563 - val_accuracy: 0.9745\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9917 - val_loss: 0.2022 - val_accuracy: 0.9613\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0872 - accuracy: 0.9927 - val_loss: 0.1361 - val_accuracy: 0.9777\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9938 - val_loss: 0.1465 - val_accuracy: 0.9772\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9909 - val_loss: 0.1438 - val_accuracy: 0.9753\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9941 - val_loss: 0.1407 - val_accuracy: 0.9777\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9951 - val_loss: 0.1478 - val_accuracy: 0.9767\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.9953 - val_loss: 0.1462 - val_accuracy: 0.9770\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9963 - val_loss: 0.1573 - val_accuracy: 0.9743\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.9967 - val_loss: 0.1454 - val_accuracy: 0.9772\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9973 - val_loss: 0.1471 - val_accuracy: 0.9783\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9979 - val_loss: 0.2099 - val_accuracy: 0.9610\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.9980 - val_loss: 0.1430 - val_accuracy: 0.9783\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9980 - val_loss: 0.1443 - val_accuracy: 0.9790\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1143 - accuracy: 0.9892 - val_loss: 0.1799 - val_accuracy: 0.9622\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9894 - val_loss: 0.1428 - val_accuracy: 0.9756\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9949 - val_loss: 0.1412 - val_accuracy: 0.9763\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0676 - accuracy: 0.9963 - val_loss: 0.1385 - val_accuracy: 0.9773\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9978 - val_loss: 0.1377 - val_accuracy: 0.9790\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.9986 - val_loss: 0.1382 - val_accuracy: 0.9783\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0593 - accuracy: 0.9988 - val_loss: 0.1394 - val_accuracy: 0.9786\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0574 - accuracy: 0.9993 - val_loss: 0.1424 - val_accuracy: 0.9778\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9995 - val_loss: 0.1351 - val_accuracy: 0.9794\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.9994 - val_loss: 0.1487 - val_accuracy: 0.9783\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0543 - accuracy: 0.9997 - val_loss: 0.1348 - val_accuracy: 0.9803\n",
      "Test loss: 0.13476115465164185, Test accuracy 0.9803000092506409\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6141 - accuracy: 0.8288 - val_loss: 0.2902 - val_accuracy: 0.9331\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2634 - accuracy: 0.9410 - val_loss: 0.2362 - val_accuracy: 0.9497\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2144 - accuracy: 0.9561 - val_loss: 0.2010 - val_accuracy: 0.9619\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1860 - accuracy: 0.9646 - val_loss: 0.1892 - val_accuracy: 0.9644\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1687 - accuracy: 0.9694 - val_loss: 0.1784 - val_accuracy: 0.9670\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9741 - val_loss: 0.1611 - val_accuracy: 0.9716\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1432 - accuracy: 0.9768 - val_loss: 0.1629 - val_accuracy: 0.9710\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1358 - accuracy: 0.9792 - val_loss: 0.1520 - val_accuracy: 0.9731\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9817 - val_loss: 0.1503 - val_accuracy: 0.9736\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1210 - accuracy: 0.9831 - val_loss: 0.1752 - val_accuracy: 0.9675\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1185 - accuracy: 0.9841 - val_loss: 0.1511 - val_accuracy: 0.9745\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1120 - accuracy: 0.9854 - val_loss: 0.1502 - val_accuracy: 0.9749\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1079 - accuracy: 0.9869 - val_loss: 0.1476 - val_accuracy: 0.9757\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1023 - accuracy: 0.9886 - val_loss: 0.1533 - val_accuracy: 0.9741\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0985 - accuracy: 0.9894 - val_loss: 0.1434 - val_accuracy: 0.9757\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9903 - val_loss: 0.1393 - val_accuracy: 0.9776\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0926 - accuracy: 0.9911 - val_loss: 0.1409 - val_accuracy: 0.9760\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0895 - accuracy: 0.9919 - val_loss: 0.1425 - val_accuracy: 0.9776\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0857 - accuracy: 0.9937 - val_loss: 0.1501 - val_accuracy: 0.9755\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0844 - accuracy: 0.9935 - val_loss: 0.1403 - val_accuracy: 0.9788\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9944 - val_loss: 0.1449 - val_accuracy: 0.9748\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1835 - accuracy: 0.9735 - val_loss: 0.1680 - val_accuracy: 0.9683\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9867 - val_loss: 0.1439 - val_accuracy: 0.9747\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9916 - val_loss: 0.1531 - val_accuracy: 0.9750\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0821 - accuracy: 0.9934 - val_loss: 0.1463 - val_accuracy: 0.9757\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.9947 - val_loss: 0.1424 - val_accuracy: 0.9775\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9953 - val_loss: 0.1406 - val_accuracy: 0.9786\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9966 - val_loss: 0.1443 - val_accuracy: 0.9783\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9963 - val_loss: 0.1463 - val_accuracy: 0.9771\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0687 - accuracy: 0.9972 - val_loss: 0.1422 - val_accuracy: 0.9783\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.9984 - val_loss: 0.1749 - val_accuracy: 0.9711\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9967 - val_loss: 0.1417 - val_accuracy: 0.9775\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9978 - val_loss: 0.1474 - val_accuracy: 0.9750\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0635 - accuracy: 0.9983 - val_loss: 0.1457 - val_accuracy: 0.9767\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9989 - val_loss: 0.1428 - val_accuracy: 0.9793\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0616 - accuracy: 0.9986 - val_loss: 0.1507 - val_accuracy: 0.9760\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9995 - val_loss: 0.1370 - val_accuracy: 0.9794\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.9996 - val_loss: 0.1366 - val_accuracy: 0.9794\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.9998 - val_loss: 0.1338 - val_accuracy: 0.9803\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0546 - accuracy: 0.9998 - val_loss: 0.1366 - val_accuracy: 0.9791\n",
      "Test loss: 0.13660095632076263, Test accuracy 0.9790999889373779\n",
      "mean =  0.9798666636149088\n",
      "std =  0.0005436563716422689\n"
     ]
    }
   ],
   "source": [
    "#regularization factor 0.0001\n",
    "for _ in range(3):\n",
    "    model_4 = Sequential()\n",
    "    model_4.add(Flatten())\n",
    "    model_4.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "    model_4.add(Dense(64, activation = 'relu',kernel_regularizer=regularizers.L2(0.0001)))\n",
    "    model_4.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L2(0.0001)))\n",
    "    model_4.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L2(0.0001)))\n",
    "\n",
    "    model_4.add(Dense(num_classes, activation='softmax'))\n",
    "    model_4.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),metrics=['accuracy'],)\n",
    "    epochs = 40\n",
    "    fit_info = model_4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "    val_acc_0_0001.append(fit_info.history['val_accuracy'][-1])\n",
    "\n",
    "mean_0_0001= np.mean(val_acc_0_0001)\n",
    "std_0_0001=np.std(val_acc_0_0001)\n",
    "print('mean = ', mean_0_0001)\n",
    "print('std = ', std_0_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9108 - accuracy: 0.8187 - val_loss: 0.5698 - val_accuracy: 0.9273\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5249 - accuracy: 0.9366 - val_loss: 0.4658 - val_accuracy: 0.9519\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4489 - accuracy: 0.9536 - val_loss: 0.4221 - val_accuracy: 0.9573\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4042 - accuracy: 0.9613 - val_loss: 0.3849 - val_accuracy: 0.9633\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3668 - accuracy: 0.9674 - val_loss: 0.3665 - val_accuracy: 0.9630\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3363 - accuracy: 0.9715 - val_loss: 0.3522 - val_accuracy: 0.9618\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3115 - accuracy: 0.9741 - val_loss: 0.3274 - val_accuracy: 0.9678\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2904 - accuracy: 0.9755 - val_loss: 0.3023 - val_accuracy: 0.9694\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2709 - accuracy: 0.9781 - val_loss: 0.2832 - val_accuracy: 0.9712\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2542 - accuracy: 0.9798 - val_loss: 0.2662 - val_accuracy: 0.9719\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2374 - accuracy: 0.9812 - val_loss: 0.2620 - val_accuracy: 0.9698\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2234 - accuracy: 0.9831 - val_loss: 0.2467 - val_accuracy: 0.9721\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2115 - accuracy: 0.9837 - val_loss: 0.2371 - val_accuracy: 0.9740\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1994 - accuracy: 0.9847 - val_loss: 0.2269 - val_accuracy: 0.9740\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1892 - accuracy: 0.9854 - val_loss: 0.2200 - val_accuracy: 0.9738\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9866 - val_loss: 0.2128 - val_accuracy: 0.9755\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1710 - accuracy: 0.9870 - val_loss: 0.2059 - val_accuracy: 0.9740\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1634 - accuracy: 0.9878 - val_loss: 0.1954 - val_accuracy: 0.9762\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1934 - accuracy: 0.9794 - val_loss: 0.1949 - val_accuracy: 0.9746\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1574 - accuracy: 0.9867 - val_loss: 0.1884 - val_accuracy: 0.9761\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1478 - accuracy: 0.9887 - val_loss: 0.1834 - val_accuracy: 0.9761\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9884 - val_loss: 0.1950 - val_accuracy: 0.9726\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9891 - val_loss: 0.1660 - val_accuracy: 0.9790\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9909 - val_loss: 0.1634 - val_accuracy: 0.9806\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9911 - val_loss: 0.1815 - val_accuracy: 0.9722\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9914 - val_loss: 0.1568 - val_accuracy: 0.9787\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9916 - val_loss: 0.1510 - val_accuracy: 0.9805\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1136 - accuracy: 0.9920 - val_loss: 0.1592 - val_accuracy: 0.9761\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9862 - val_loss: 0.1607 - val_accuracy: 0.9775\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9916 - val_loss: 0.1491 - val_accuracy: 0.9799\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9915 - val_loss: 0.1630 - val_accuracy: 0.9746\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1038 - accuracy: 0.9927 - val_loss: 0.1629 - val_accuracy: 0.9724\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1018 - accuracy: 0.9928 - val_loss: 0.1426 - val_accuracy: 0.9779\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0984 - accuracy: 0.9931 - val_loss: 0.1422 - val_accuracy: 0.9782\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0981 - accuracy: 0.9926 - val_loss: 0.1398 - val_accuracy: 0.9788\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9932 - val_loss: 0.1418 - val_accuracy: 0.9777\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9927 - val_loss: 0.1401 - val_accuracy: 0.9791\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0928 - accuracy: 0.9935 - val_loss: 0.1427 - val_accuracy: 0.9779\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0902 - accuracy: 0.9939 - val_loss: 0.1330 - val_accuracy: 0.9782\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1371 - accuracy: 0.9819 - val_loss: 0.1437 - val_accuracy: 0.9747\n",
      "Test loss: 0.143682599067688, Test accuracy 0.9746999740600586\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8921 - accuracy: 0.8242 - val_loss: 0.5703 - val_accuracy: 0.9232\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5107 - accuracy: 0.9417 - val_loss: 0.4942 - val_accuracy: 0.9427\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4403 - accuracy: 0.9557 - val_loss: 0.4097 - val_accuracy: 0.9609\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3953 - accuracy: 0.9641 - val_loss: 0.3919 - val_accuracy: 0.9608\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3641 - accuracy: 0.9681 - val_loss: 0.3589 - val_accuracy: 0.9669\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3305 - accuracy: 0.9728 - val_loss: 0.3307 - val_accuracy: 0.9704\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3057 - accuracy: 0.9755 - val_loss: 0.3402 - val_accuracy: 0.9640\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.9775 - val_loss: 0.3014 - val_accuracy: 0.9715\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.9803 - val_loss: 0.2876 - val_accuracy: 0.9713\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2477 - accuracy: 0.9814 - val_loss: 0.3255 - val_accuracy: 0.9511\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9831 - val_loss: 0.2814 - val_accuracy: 0.9652\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2190 - accuracy: 0.9839 - val_loss: 0.2725 - val_accuracy: 0.9658\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2074 - accuracy: 0.9852 - val_loss: 0.2269 - val_accuracy: 0.9769\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1979 - accuracy: 0.9851 - val_loss: 0.2344 - val_accuracy: 0.9714\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9866 - val_loss: 0.2116 - val_accuracy: 0.9766\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1767 - accuracy: 0.9872 - val_loss: 0.2074 - val_accuracy: 0.9759\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1681 - accuracy: 0.9879 - val_loss: 0.2069 - val_accuracy: 0.9745\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1640 - accuracy: 0.9876 - val_loss: 0.1999 - val_accuracy: 0.9744\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1546 - accuracy: 0.9886 - val_loss: 0.1892 - val_accuracy: 0.9760\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1485 - accuracy: 0.9889 - val_loss: 0.1830 - val_accuracy: 0.9768\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1478 - accuracy: 0.9883 - val_loss: 0.1870 - val_accuracy: 0.9769\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1369 - accuracy: 0.9901 - val_loss: 0.1777 - val_accuracy: 0.9774\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1578 - accuracy: 0.9846 - val_loss: 0.1772 - val_accuracy: 0.9753\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1341 - accuracy: 0.9889 - val_loss: 0.1697 - val_accuracy: 0.9778\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1242 - accuracy: 0.9912 - val_loss: 0.1743 - val_accuracy: 0.9745\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1205 - accuracy: 0.9913 - val_loss: 0.1599 - val_accuracy: 0.9777\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1685 - accuracy: 0.9790 - val_loss: 0.1709 - val_accuracy: 0.9737\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9905 - val_loss: 0.1566 - val_accuracy: 0.9785\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9917 - val_loss: 0.1507 - val_accuracy: 0.9790\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1088 - accuracy: 0.9923 - val_loss: 0.1577 - val_accuracy: 0.9755\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1050 - accuracy: 0.9929 - val_loss: 0.1545 - val_accuracy: 0.9761\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1042 - accuracy: 0.9923 - val_loss: 0.1563 - val_accuracy: 0.9757\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1005 - accuracy: 0.9928 - val_loss: 0.1472 - val_accuracy: 0.9780\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0975 - accuracy: 0.9935 - val_loss: 0.1441 - val_accuracy: 0.9770\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9940 - val_loss: 0.1477 - val_accuracy: 0.9760\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0950 - accuracy: 0.9932 - val_loss: 0.1429 - val_accuracy: 0.9789\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1823 - accuracy: 0.9722 - val_loss: 0.1525 - val_accuracy: 0.9759\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1072 - accuracy: 0.9888 - val_loss: 0.1707 - val_accuracy: 0.9708\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0999 - accuracy: 0.9913 - val_loss: 0.1434 - val_accuracy: 0.9780\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9926 - val_loss: 0.1462 - val_accuracy: 0.9770\n",
      "Test loss: 0.14624139666557312, Test accuracy 0.9769999980926514\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9069 - accuracy: 0.8245 - val_loss: 0.5758 - val_accuracy: 0.9225\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5223 - accuracy: 0.9370 - val_loss: 0.4917 - val_accuracy: 0.9447\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4471 - accuracy: 0.9548 - val_loss: 0.4580 - val_accuracy: 0.9473\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4003 - accuracy: 0.9631 - val_loss: 0.3867 - val_accuracy: 0.9621\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3636 - accuracy: 0.9682 - val_loss: 0.3609 - val_accuracy: 0.9648\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3336 - accuracy: 0.9714 - val_loss: 0.3427 - val_accuracy: 0.9665\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3087 - accuracy: 0.9747 - val_loss: 0.3191 - val_accuracy: 0.9676\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.9769 - val_loss: 0.2921 - val_accuracy: 0.9698\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2686 - accuracy: 0.9790 - val_loss: 0.2873 - val_accuracy: 0.9693\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2505 - accuracy: 0.9812 - val_loss: 0.2695 - val_accuracy: 0.9700\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2343 - accuracy: 0.9827 - val_loss: 0.2656 - val_accuracy: 0.9702\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2217 - accuracy: 0.9836 - val_loss: 0.2507 - val_accuracy: 0.9700\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2084 - accuracy: 0.9847 - val_loss: 0.2468 - val_accuracy: 0.9703\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9861 - val_loss: 0.2271 - val_accuracy: 0.9737\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1970 - accuracy: 0.9839 - val_loss: 0.2312 - val_accuracy: 0.9709\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1789 - accuracy: 0.9868 - val_loss: 0.2114 - val_accuracy: 0.9730\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1693 - accuracy: 0.9877 - val_loss: 0.2039 - val_accuracy: 0.9743\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1622 - accuracy: 0.9884 - val_loss: 0.2096 - val_accuracy: 0.9702\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9894 - val_loss: 0.2027 - val_accuracy: 0.9730\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1525 - accuracy: 0.9882 - val_loss: 0.1863 - val_accuracy: 0.9751\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1424 - accuracy: 0.9900 - val_loss: 0.1875 - val_accuracy: 0.9746\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1366 - accuracy: 0.9906 - val_loss: 0.1873 - val_accuracy: 0.9720\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1316 - accuracy: 0.9908 - val_loss: 0.1887 - val_accuracy: 0.9732\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1269 - accuracy: 0.9911 - val_loss: 0.1707 - val_accuracy: 0.9756\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1236 - accuracy: 0.9913 - val_loss: 0.1693 - val_accuracy: 0.9755\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1197 - accuracy: 0.9915 - val_loss: 0.1663 - val_accuracy: 0.9764\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9916 - val_loss: 0.1636 - val_accuracy: 0.9755\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1154 - accuracy: 0.9913 - val_loss: 0.1793 - val_accuracy: 0.9710\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1136 - accuracy: 0.9912 - val_loss: 0.1621 - val_accuracy: 0.9741\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1638 - accuracy: 0.9813 - val_loss: 0.3098 - val_accuracy: 0.9410\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1481 - accuracy: 0.9799 - val_loss: 0.1845 - val_accuracy: 0.9686\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1201 - accuracy: 0.9877 - val_loss: 0.1644 - val_accuracy: 0.9752\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9895 - val_loss: 0.1521 - val_accuracy: 0.9764\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1102 - accuracy: 0.9898 - val_loss: 0.1570 - val_accuracy: 0.9758\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1072 - accuracy: 0.9906 - val_loss: 0.1537 - val_accuracy: 0.9752\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1047 - accuracy: 0.9905 - val_loss: 0.1781 - val_accuracy: 0.9687\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9915 - val_loss: 0.1449 - val_accuracy: 0.9776\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9926 - val_loss: 0.1427 - val_accuracy: 0.9779\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1636 - accuracy: 0.9802 - val_loss: 0.2169 - val_accuracy: 0.9582\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1330 - accuracy: 0.9810 - val_loss: 0.1539 - val_accuracy: 0.9740\n",
      "Test loss: 0.15386046469211578, Test accuracy 0.9739999771118164\n",
      "mean =  0.9752333164215088\n",
      "std =  0.0012815022505508768\n"
     ]
    }
   ],
   "source": [
    "#regularization factor 0.0005\n",
    "for _ in range(3):\n",
    "    model_5 = Sequential()\n",
    "    model_5.add(Flatten())\n",
    "    model_5.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.L2(0.0005)))\n",
    "    model_5.add(Dense(64, activation = 'relu',kernel_regularizer=regularizers.L2(0.0005)))\n",
    "    model_5.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L2(0.0005)))\n",
    "    model_5.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L2(0.0005)))\n",
    "\n",
    "    model_5.add(Dense(num_classes, activation='softmax'))\n",
    "    model_5.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),metrics=['accuracy'],)\n",
    "    epochs = 40\n",
    "    fit_info = model_5.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model_5.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "    val_acc_0_0005.append(fit_info.history['val_accuracy'][-1])\n",
    "\n",
    "mean_0_0005 = np.mean(val_acc_0_0005)\n",
    "std_0_0005 =np.std(val_acc_0_0005)\n",
    "print('mean = ', mean_0_0005)\n",
    "print('std = ', std_0_0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5708 - accuracy: 0.8252 - val_loss: 0.2260 - val_accuracy: 0.9352\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1985 - accuracy: 0.9422 - val_loss: 0.1627 - val_accuracy: 0.9516\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1437 - accuracy: 0.9587 - val_loss: 0.1594 - val_accuracy: 0.9519\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1185 - accuracy: 0.9661 - val_loss: 0.1399 - val_accuracy: 0.9600\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9718 - val_loss: 0.1021 - val_accuracy: 0.9699\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 0.1119 - val_accuracy: 0.9680\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0793 - accuracy: 0.9774 - val_loss: 0.0944 - val_accuracy: 0.9734\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9809 - val_loss: 0.1062 - val_accuracy: 0.9718\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 0.0995 - val_accuracy: 0.9724\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0583 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9730\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0512 - accuracy: 0.9866 - val_loss: 0.0926 - val_accuracy: 0.9756\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.1097 - val_accuracy: 0.9714\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9888 - val_loss: 0.0941 - val_accuracy: 0.9756\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 0.1246 - val_accuracy: 0.9659\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 0.0967 - val_accuracy: 0.9751\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.1006 - val_accuracy: 0.9743\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.1096 - val_accuracy: 0.9714\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9935 - val_loss: 0.1135 - val_accuracy: 0.9716\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0265 - accuracy: 0.9947 - val_loss: 0.1034 - val_accuracy: 0.9747\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.1098 - val_accuracy: 0.9742\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.1010 - val_accuracy: 0.9761\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.9961 - val_loss: 0.1100 - val_accuracy: 0.9729\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 0.1030 - val_accuracy: 0.9767\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.1072 - val_accuracy: 0.9758\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.9965 - val_loss: 0.1044 - val_accuracy: 0.9779\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 0.1016 - val_accuracy: 0.9780\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9977 - val_loss: 0.1338 - val_accuracy: 0.9730\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9982 - val_loss: 0.1117 - val_accuracy: 0.9770\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.1121 - val_accuracy: 0.9767\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9996 - val_loss: 0.1141 - val_accuracy: 0.9762\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9997 - val_loss: 0.1116 - val_accuracy: 0.9775\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9997 - val_loss: 0.1130 - val_accuracy: 0.9770\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9999 - val_loss: 0.1130 - val_accuracy: 0.9776\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9770\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9779\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9773\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9774\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9772\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9780\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9772\n",
      "Test loss: 0.12269796431064606, Test accuracy 0.9771999716758728\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5515 - accuracy: 0.8324 - val_loss: 0.2532 - val_accuracy: 0.9237\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2051 - accuracy: 0.9401 - val_loss: 0.1651 - val_accuracy: 0.9504\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9551 - val_loss: 0.1419 - val_accuracy: 0.9563\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1235 - accuracy: 0.9646 - val_loss: 0.1561 - val_accuracy: 0.9551\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9698 - val_loss: 0.1200 - val_accuracy: 0.9639\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 0.1139 - val_accuracy: 0.9653\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9777 - val_loss: 0.1068 - val_accuracy: 0.9675\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9806 - val_loss: 0.1079 - val_accuracy: 0.9681\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0986 - val_accuracy: 0.9714\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9841 - val_loss: 0.0902 - val_accuracy: 0.9747\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0530 - accuracy: 0.9862 - val_loss: 0.0905 - val_accuracy: 0.9752\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.9874 - val_loss: 0.1002 - val_accuracy: 0.9710\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 0.1050 - val_accuracy: 0.9722\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.9885 - val_loss: 0.0963 - val_accuracy: 0.9735\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.9910 - val_loss: 0.0990 - val_accuracy: 0.9732\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0327 - accuracy: 0.9927 - val_loss: 0.0999 - val_accuracy: 0.9739\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9935 - val_loss: 0.1032 - val_accuracy: 0.9731\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0278 - accuracy: 0.9943 - val_loss: 0.0923 - val_accuracy: 0.9777\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9945 - val_loss: 0.1097 - val_accuracy: 0.9731\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9915 - val_loss: 0.0953 - val_accuracy: 0.9753\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9945 - val_loss: 0.0940 - val_accuracy: 0.9764\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 0.0997 - val_accuracy: 0.9759\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.1138 - val_accuracy: 0.9747\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.1014 - val_accuracy: 0.9774\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0161 - accuracy: 0.9980 - val_loss: 0.1028 - val_accuracy: 0.9771\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9984 - val_loss: 0.1039 - val_accuracy: 0.9784\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 0.1130 - val_accuracy: 0.9764\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9988 - val_loss: 0.1194 - val_accuracy: 0.9762\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.9981 - val_loss: 0.1137 - val_accuracy: 0.9765\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0120 - accuracy: 0.9993 - val_loss: 0.1106 - val_accuracy: 0.9780\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9996 - val_loss: 0.1226 - val_accuracy: 0.9762\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9998 - val_loss: 0.1156 - val_accuracy: 0.9779\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.1215 - val_accuracy: 0.9760\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.1245 - val_accuracy: 0.9757\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9999 - val_loss: 0.1183 - val_accuracy: 0.9776\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.1194 - val_accuracy: 0.9767\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9775\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9747\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9999 - val_loss: 0.1219 - val_accuracy: 0.9766\n",
      "Test loss: 0.12192805111408234, Test accuracy 0.9765999913215637\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5616 - accuracy: 0.8229 - val_loss: 0.2500 - val_accuracy: 0.9249\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2061 - accuracy: 0.9391 - val_loss: 0.1964 - val_accuracy: 0.9397\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1515 - accuracy: 0.9563 - val_loss: 0.1332 - val_accuracy: 0.9608\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1218 - accuracy: 0.9651 - val_loss: 0.1267 - val_accuracy: 0.9639\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1029 - accuracy: 0.9709 - val_loss: 0.1136 - val_accuracy: 0.9649\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.9751 - val_loss: 0.1082 - val_accuracy: 0.9667\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0805 - accuracy: 0.9776 - val_loss: 0.0984 - val_accuracy: 0.9708\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9800 - val_loss: 0.1112 - val_accuracy: 0.9658\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0657 - accuracy: 0.9817 - val_loss: 0.0906 - val_accuracy: 0.9724\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9832 - val_loss: 0.0937 - val_accuracy: 0.9739\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9851 - val_loss: 0.0912 - val_accuracy: 0.9735\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9866 - val_loss: 0.0900 - val_accuracy: 0.9735\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.1207 - val_accuracy: 0.9639\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9896 - val_loss: 0.0996 - val_accuracy: 0.9720\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.0982 - val_accuracy: 0.9733\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0353 - accuracy: 0.9918 - val_loss: 0.0977 - val_accuracy: 0.9734\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.1018 - val_accuracy: 0.9721\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0268 - accuracy: 0.9943 - val_loss: 0.0947 - val_accuracy: 0.9740\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0280 - accuracy: 0.9942 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9955 - val_loss: 0.0983 - val_accuracy: 0.9745\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.9961 - val_loss: 0.0940 - val_accuracy: 0.9757\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.9955 - val_loss: 0.1022 - val_accuracy: 0.9758\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0218 - accuracy: 0.9959 - val_loss: 0.0932 - val_accuracy: 0.9768\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9974 - val_loss: 0.1066 - val_accuracy: 0.9750\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 0.1178 - val_accuracy: 0.9740\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0178 - accuracy: 0.9973 - val_loss: 0.1047 - val_accuracy: 0.9770\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9981 - val_loss: 0.1031 - val_accuracy: 0.9775\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9981 - val_loss: 0.1001 - val_accuracy: 0.9776\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9994 - val_loss: 0.1074 - val_accuracy: 0.9770\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9997 - val_loss: 0.1034 - val_accuracy: 0.9792\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9998 - val_loss: 0.1064 - val_accuracy: 0.9785\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.1163 - val_accuracy: 0.9766\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 0.1039 - val_accuracy: 0.9795\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9998 - val_loss: 0.1071 - val_accuracy: 0.9791\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0101 - accuracy: 0.9999 - val_loss: 0.1085 - val_accuracy: 0.9787\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0098 - accuracy: 0.9999 - val_loss: 0.1084 - val_accuracy: 0.9794\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9996 - val_loss: 0.1085 - val_accuracy: 0.9785\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9999 - val_loss: 0.1101 - val_accuracy: 0.9784\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9794\n",
      "Test loss: 0.11109957098960876, Test accuracy 0.9793999791145325\n",
      "mean =  0.977733314037323\n",
      "std =  0.0012036952731987324\n"
     ]
    }
   ],
   "source": [
    "#regularization factor 0.00001\n",
    "for _ in range(3):\n",
    "    model_6 = Sequential()\n",
    "    model_6.add(Flatten())\n",
    "    model_6.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.L2(0.00001)))\n",
    "    model_6.add(Dense(64, activation = 'relu',kernel_regularizer=regularizers.L2(0.00001)))\n",
    "    model_6.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L2(0.00001)))\n",
    "    model_6.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L2(0.00001)))\n",
    "\n",
    "    model_6.add(Dense(num_classes, activation='softmax'))\n",
    "    model_6.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),metrics=['accuracy'],)\n",
    "    epochs = 40\n",
    "    fit_info = model_6.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model_6.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "    val_acc_0_00001.append(fit_info.history['val_accuracy'][-1])\n",
    "\n",
    "mean_0_00001= np.mean(val_acc_0_00001)\n",
    "std_0_00001=np.std(val_acc_0_00001)\n",
    "print('mean = ', mean_0_00001)\n",
    "print('std = ', std_0_00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5571 - accuracy: 0.8257 - val_loss: 0.2070 - val_accuracy: 0.9379\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1904 - accuracy: 0.9432 - val_loss: 0.1674 - val_accuracy: 0.9499\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1391 - accuracy: 0.9574 - val_loss: 0.1445 - val_accuracy: 0.9553\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1131 - accuracy: 0.9659 - val_loss: 0.1230 - val_accuracy: 0.9617\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9710 - val_loss: 0.1309 - val_accuracy: 0.9584\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9751 - val_loss: 0.1014 - val_accuracy: 0.9682\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.9780 - val_loss: 0.0922 - val_accuracy: 0.9707\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 0.0927 - val_accuracy: 0.9717\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.0976 - val_accuracy: 0.9711\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.0838 - val_accuracy: 0.9757\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.0953 - val_accuracy: 0.9710\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0908 - val_accuracy: 0.9735\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0929 - val_accuracy: 0.9735\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0904 - val_accuracy: 0.9746\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9812 - val_loss: 0.0949 - val_accuracy: 0.9721\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 0.0867 - val_accuracy: 0.9770\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.0964 - val_accuracy: 0.9739\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0865 - val_accuracy: 0.9785\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0943 - val_accuracy: 0.9766\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0909 - val_accuracy: 0.9764\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0999 - val_accuracy: 0.9761\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0904 - val_accuracy: 0.9772\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.1026 - val_accuracy: 0.9761\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.1029 - val_accuracy: 0.9766\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1022 - val_accuracy: 0.9771\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.1071 - val_accuracy: 0.9763\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1051 - val_accuracy: 0.9766\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1265 - val_accuracy: 0.9737\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.1057 - val_accuracy: 0.9776\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.1102 - val_accuracy: 0.9778\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.1069 - val_accuracy: 0.9796\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.1104 - val_accuracy: 0.9790\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.1103 - val_accuracy: 0.9792\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9784\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.1153 - val_accuracy: 0.9788\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.2843 - val_accuracy: 0.9518\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1368 - val_accuracy: 0.9728\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.1139 - val_accuracy: 0.9762\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.1217 - val_accuracy: 0.9763\n",
      "Test loss: 0.12173327803611755, Test accuracy 0.9763000011444092\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.5413 - accuracy: 0.8314 - val_loss: 0.2617 - val_accuracy: 0.9153\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1949 - accuracy: 0.9406 - val_loss: 0.1483 - val_accuracy: 0.9559\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1435 - accuracy: 0.9568 - val_loss: 0.1652 - val_accuracy: 0.9492\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1148 - accuracy: 0.9655 - val_loss: 0.1170 - val_accuracy: 0.9638\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0984 - accuracy: 0.9706 - val_loss: 0.1206 - val_accuracy: 0.9636\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9754 - val_loss: 0.1087 - val_accuracy: 0.9674\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.0884 - val_accuracy: 0.9741\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0635 - accuracy: 0.9808 - val_loss: 0.1027 - val_accuracy: 0.9680\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.1038 - val_accuracy: 0.9682\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0980 - val_accuracy: 0.9723\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0867 - val_accuracy: 0.9747\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.0849 - val_accuracy: 0.9739\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0861 - val_accuracy: 0.9748\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0900 - val_accuracy: 0.9750\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0850 - val_accuracy: 0.9761\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 0.0842 - val_accuracy: 0.9760\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0919 - val_accuracy: 0.9767\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.1023 - val_accuracy: 0.9744\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0983 - val_accuracy: 0.9742\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0955 - val_accuracy: 0.9765\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1118 - val_accuracy: 0.9746\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.1020 - val_accuracy: 0.9763\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1047 - val_accuracy: 0.9749\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0980 - val_accuracy: 0.9768\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.1069 - val_accuracy: 0.9760\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1217 - val_accuracy: 0.9741\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.1005 - val_accuracy: 0.9778\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0991 - val_accuracy: 0.9781\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0988 - val_accuracy: 0.9795\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1000 - val_accuracy: 0.9797\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.1014 - val_accuracy: 0.9795\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.1056 - val_accuracy: 0.9789\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.1071 - val_accuracy: 0.9789\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.1058 - val_accuracy: 0.9797\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9791\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9790\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9787\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9787\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9791\n",
      "Test loss: 0.11460333317518234, Test accuracy 0.9790999889373779\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5443 - accuracy: 0.8324 - val_loss: 0.2285 - val_accuracy: 0.9310\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2004 - accuracy: 0.9401 - val_loss: 0.1753 - val_accuracy: 0.9461\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9562 - val_loss: 0.1377 - val_accuracy: 0.9563\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1122 - accuracy: 0.9664 - val_loss: 0.1068 - val_accuracy: 0.9683\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0941 - accuracy: 0.9715 - val_loss: 0.1253 - val_accuracy: 0.9613\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9754 - val_loss: 0.0933 - val_accuracy: 0.9706\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.0984 - val_accuracy: 0.9704\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.0913 - val_accuracy: 0.9734\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0559 - accuracy: 0.9830 - val_loss: 0.0923 - val_accuracy: 0.9734\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.0835 - val_accuracy: 0.9756\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0940 - val_accuracy: 0.9738\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.9876 - val_loss: 0.0938 - val_accuracy: 0.9737\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.0973 - val_accuracy: 0.9732\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0876 - val_accuracy: 0.9762\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.0994 - val_accuracy: 0.9749\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 0.0816 - val_accuracy: 0.9773\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0949 - val_accuracy: 0.9758\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0893 - val_accuracy: 0.9769\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.1091 - val_accuracy: 0.9702\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0936 - val_accuracy: 0.9777\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1045 - val_accuracy: 0.9752\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.1001 - val_accuracy: 0.9741\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.1143 - val_accuracy: 0.9740\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.1096 - val_accuracy: 0.9743\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1019 - val_accuracy: 0.9773\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1055 - val_accuracy: 0.9776\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1082 - val_accuracy: 0.9782\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1064 - val_accuracy: 0.9779\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1146 - val_accuracy: 0.9763\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1177 - val_accuracy: 0.9755\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.1174 - val_accuracy: 0.9771\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.1147 - val_accuracy: 0.9780\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.1166 - val_accuracy: 0.9779\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.1192 - val_accuracy: 0.9771\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.1185 - val_accuracy: 0.9774\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9771\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9780\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.1232 - val_accuracy: 0.9780\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9780\n",
      "Test loss: 0.12396488338708878, Test accuracy 0.9779999852180481\n",
      "mean =  0.9777999917666117\n",
      "std =  0.001151804655213309\n"
     ]
    }
   ],
   "source": [
    "#regularization factor 0.000001\n",
    "for _ in range(3):\n",
    "    model_7 = Sequential()\n",
    "    model_7.add(Flatten())\n",
    "    model_7.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.L2(0.000001)))\n",
    "    model_7.add(Dense(64, activation = 'relu',kernel_regularizer=regularizers.L2(0.000001)))\n",
    "    model_7.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L2(0.000001)))\n",
    "    model_7.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L2(0.000001)))\n",
    "\n",
    "    model_7.add(Dense(num_classes, activation='softmax'))\n",
    "    model_7.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),metrics=['accuracy'],)\n",
    "    epochs = 40\n",
    "    fit_info = model_7.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model_7.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "    val_acc_0_000001.append(fit_info.history['val_accuracy'][-1])\n",
    "\n",
    "mean_0_000001= np.mean(val_acc_0_000001)\n",
    "std_0_000001=np.std(val_acc_0_000001)\n",
    "print('mean = ', mean_0_000001)\n",
    "print('std = ', std_0_000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 0.9798666636149088\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['0.001','0.0001','0.0005','0.00001','0.000001']\n",
    "means = [mean_0_001,mean_0_0001,mean_0_0005,mean_0_00001,mean_0_000001]\n",
    "stds = [std_0_001,std_0_0001,std_0_0005,std_0_00001,std_0_000001]\n",
    "x_pos = np.arange(len(labels))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, means, yerr=stds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('Validation accuracy')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('Validation accuracy with standard deviation as a function of the regularization factors.')\n",
    "ax.yaxis.grid(True)\n",
    "plt.ylim([0.96,0.985])\n",
    "print('Maximum accuracy is', np.max(means))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Design a model that makes use of at least one convolutional layer  how performant a model can you get? -- According to the MNIST database it should be possible reach to 99% accuracy on the validation data. If you choose to use any layers apart from the convolutional layers and layers that you used in previous questions, you must describe\n",
    "what they do. If you do not reach 99% accuracy, report your best performance, and explain your attempts and thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The pooling layer is applied after the Convolutional layer and is used to reduce the dimensions of the feature map, which helps in preserving the important information or features of the input image, this reduces the computation time. Max pooling takes a set of values $S$ from the convolutional layer as input and outputs $max(s_0...s_n)$.\n",
    "We need the flattened and dense layers, since this is were the actual classification takes place. The convolutional layer simply filters and transform the data.\n",
    "\n",
    "We got 99% accuracy. \n",
    "See code below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.4269 - accuracy: 0.8752 - val_loss: 0.1135 - val_accuracy: 0.9722\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.1086 - accuracy: 0.9751 - val_loss: 0.0843 - val_accuracy: 0.9824\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0869 - accuracy: 0.9814 - val_loss: 0.0713 - val_accuracy: 0.9860\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0700 - accuracy: 0.9869 - val_loss: 0.0658 - val_accuracy: 0.9878\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0616 - accuracy: 0.9893 - val_loss: 0.0588 - val_accuracy: 0.9888\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0556 - accuracy: 0.9913 - val_loss: 0.0603 - val_accuracy: 0.9889\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0511 - accuracy: 0.9927 - val_loss: 0.0573 - val_accuracy: 0.9895\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0480 - accuracy: 0.9936 - val_loss: 0.0568 - val_accuracy: 0.9904\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.0445 - accuracy: 0.9946 - val_loss: 0.1171 - val_accuracy: 0.9743\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0416 - accuracy: 0.9959 - val_loss: 0.0641 - val_accuracy: 0.9885\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0390 - accuracy: 0.9966 - val_loss: 0.0584 - val_accuracy: 0.9893\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0372 - accuracy: 0.9972 - val_loss: 0.0553 - val_accuracy: 0.9902\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0356 - accuracy: 0.9977 - val_loss: 0.0551 - val_accuracy: 0.9915\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0331 - accuracy: 0.9988 - val_loss: 0.0539 - val_accuracy: 0.9921\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0344 - accuracy: 0.9983 - val_loss: 0.0551 - val_accuracy: 0.9915\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0401 - accuracy: 0.9974 - val_loss: 0.0559 - val_accuracy: 0.9919\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0325 - accuracy: 0.9988 - val_loss: 0.0546 - val_accuracy: 0.9920\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0306 - accuracy: 0.9994 - val_loss: 0.0564 - val_accuracy: 0.9912\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 18s 37ms/step - loss: 0.0299 - accuracy: 0.9995 - val_loss: 0.0546 - val_accuracy: 0.9920\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0292 - accuracy: 0.9997 - val_loss: 0.0555 - val_accuracy: 0.9921\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0289 - accuracy: 0.9998 - val_loss: 0.0581 - val_accuracy: 0.9907\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0287 - accuracy: 0.9998 - val_loss: 0.0572 - val_accuracy: 0.9912\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0284 - accuracy: 0.9999 - val_loss: 0.0573 - val_accuracy: 0.9917\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0282 - accuracy: 0.9999 - val_loss: 0.0568 - val_accuracy: 0.9929\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0280 - accuracy: 0.9999 - val_loss: 0.0583 - val_accuracy: 0.9921\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9919\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9922\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0281 - accuracy: 0.9998 - val_loss: 0.0589 - val_accuracy: 0.9921\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9917\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9919\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9917\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9919\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9922\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9919\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 0.9919\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9922\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9922\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9922\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9921\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9919\n",
      "Test loss: 0.06033546105027199, Test accuracy 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "model_8 = Sequential()\n",
    "\n",
    "#(28,28,1) equals 28x28 pixels in grayscale\n",
    "model_8.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape = (28,28,1)))\n",
    "\n",
    "model_8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_8.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\n",
    "model_8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_8.add(Flatten())\n",
    "#A Dense layer is just a fully connected layer were a every neuron is connected to every single neuron in the layer before.\n",
    "model_8.add(Dense(500, activation = 'relu',kernel_regularizer=regularizers.L1(0.000001)))\n",
    "model_8.add(Dense(300, activation = 'relu',kernel_regularizer=regularizers.L1(0.000001)))\n",
    "\n",
    "model_8.add(Dense(num_classes, activation='softmax'))\n",
    "model_8.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),metrics=['accuracy'],)\n",
    "epochs = 40\n",
    "fit_info = model_8.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model_8.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 500)               800500    \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 300)               150300    \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991,378\n",
      "Trainable params: 991,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_8.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Discuss the differences and potential benefits of using convolutional layers over fully\n",
    "connected ones for the application?\n",
    "\n",
    "Answer:\n",
    "One huge benefit is that the neurons can represent more specific features regardsless of were on the image they are located. for example the edge of a drawn number will be detected in the same way regardless of were in the full pixel space the edge is drawn. as opposed to a fully connected layer where it might not get recognized if it's to small or it exists in the the wrong part of the image.\n",
    "The number of weights associated with a convolutional network is alot smaller than a fully dense one, this is good when we are working with high dimensional data such as images.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_7_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
