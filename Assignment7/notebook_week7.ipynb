{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHoSDyYpdh-s"
   },
   "source": [
    "Assignment 7: Neural Networks using Keras and Tensorflow Please see the associated document for questions\n",
    "\n",
    "If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "02ZYZ-WmdhwH"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJRCoRmew8Zd",
    "outputId": "8a74f963-06c8-4ba7-fb03-889e43dfa15e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I3g1RrZ0wpI"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UswCCQLS0s1I"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N7Aer42gk1W9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.8634 - val_loss: 0.2531 - val_accuracy: 0.9247\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.9324 - val_loss: 0.1930 - val_accuracy: 0.9414\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9478 - val_loss: 0.1546 - val_accuracy: 0.9523\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9572 - val_loss: 0.1338 - val_accuracy: 0.9581\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9647 - val_loss: 0.1262 - val_accuracy: 0.9599\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9691 - val_loss: 0.1131 - val_accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9729 - val_loss: 0.0997 - val_accuracy: 0.9701\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9758 - val_loss: 0.1025 - val_accuracy: 0.9693\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9780 - val_loss: 0.0901 - val_accuracy: 0.9717\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9801 - val_loss: 0.0889 - val_accuracy: 0.9722\n",
      "Test loss: 0.08893831074237823, Test accuracy 0.9721999764442444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Define model ##\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten()) # since we want all 28x28 pixels on one row\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing. In the notebook, the data is downloaded from an external server and imported into the notebook environment using the mnist.load_data() function call.\n",
    "\n",
    "1.1. Explain the data pre-processing highlighted in the notebook\n",
    "\n",
    "2. Network model, training, and changing hyper-parameters\n",
    "\n",
    "2.1. How many layers does the network in the notebook have? How many neurons does\n",
    "each layer have? What activation functions and why are these appropriate for this application? What is the total number of parameters for the network? Why do the input\n",
    "and output layers have the dimensions they have?\n",
    "\n",
    "It has four layers, the input layer has 784 (28*28) inputs, the two hidden layers in the middle have 64 neurons, the last one has 10 neurons, one representing each number from 0 to 9\n",
    "\n",
    "2.2. What loss function is used to train the network? What is the functional form (a mathematical expression) of the loss function? and how should we interpret it? Why is it\n",
    "appropriate for the problem at hand? \n",
    "\n",
    "Categorical crossentropy is the loss function used and it's mathematical formula is written as follows:\n",
    "$$L_{CE}(s_1) = {-}\\sum_{i=1}^{n} T_i Log(S_i)$$ \n",
    "\n",
    "Were $S$ is a vector with the output values after softmax application defined as: \n",
    "$$Softmax(Z) = \\frac{exp(z_j)}{\\sum{i=1}{n}exp(z_i)} for j = 1,...,n $$ \n",
    "\n",
    "where Z is the output layer.\n",
    "\n",
    "$T$ is a vector with corresponding expected value or true value. For our case only one value in the vector $T$ will be equal to 1 and the rest is 0. \n",
    "This means that categorical crossentropy only depends on $S_i$ if  $T_i = 1$. as $S_i$ approaches 1, the value of $L_{CE}$ will go to zero, and as the value of $S_i$ approaches 0 $L_{CE}$ goes to infinity\n",
    "\n",
    "Categorical crossentropy is good for our model since we want our model to choose between 10 different classes, and the categorical crossentropy function works for an arbitrary number of classes, as opposed to the binary crossentropy function which can only put things into two categories.\n",
    "\n",
    "Softmax is continously differentiable function, which means that we can take the partial derivative of $$L_{CE}$$ and any of the weights to minimize the value. (why? how?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Train the network for 10 epochs and plot the training and validation accuracy for each\n",
    "epoch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. Update the model to implement a three-layer neural network where the hidden layers\n",
    "have 500 and 300 hidden units respectively. Train for 40 epochs. What is the best validation accuracy you can achieve? – Geoff Hinton (a co-pioneer of Deep learning)\n",
    "claimed this network could reach a validation accuracy of 0.9847\n",
    "(http://yann.lecun.com/exdb/mnist/) using weight decay (L2 regularization of weights 2\n",
    "\n",
    "(kernels): https://keras.io/api/layers/regularizers/). Implement weight decay on hidden units and train and select 5 regularization factors from 0.000001 to 0.001. Train 3\n",
    "replicates networks for each regularization factor. Plot the final validation accuracy\n",
    "with standard deviation (computed from the replicates) as a function of the regularization factor. How close do you get to Hintons result? – If you do not get the same\n",
    "results, what factors may influence this? (hint: What information is not given by Hinton\n",
    "on the MNIST database that may influence Model training)\n",
    "\n",
    "\n",
    "L1 makes the network sparse, the sum of the absolute values are added to the loss\n",
    " L2 add the sum of the squared values of the weights to the loss, punishment is more severe\n",
    " \n",
    " alpha parameter: how much attention to pay to this penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3974 - accuracy: 0.8892 - val_loss: 0.2151 - val_accuracy: 0.9369\n",
      "Epoch 2/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1897 - accuracy: 0.9451 - val_loss: 0.1699 - val_accuracy: 0.9506\n",
      "Epoch 3/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1391 - accuracy: 0.9600 - val_loss: 0.1349 - val_accuracy: 0.9593\n",
      "Epoch 4/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1111 - accuracy: 0.9687 - val_loss: 0.1117 - val_accuracy: 0.9667\n",
      "Epoch 5/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0905 - accuracy: 0.9739 - val_loss: 0.0975 - val_accuracy: 0.9727\n",
      "Epoch 6/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9786 - val_loss: 0.1015 - val_accuracy: 0.9692\n",
      "Epoch 7/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.9822 - val_loss: 0.0829 - val_accuracy: 0.9753\n",
      "Epoch 8/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9846 - val_loss: 0.0783 - val_accuracy: 0.9765\n",
      "Epoch 9/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0714 - val_accuracy: 0.9775\n",
      "Epoch 10/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 0.0701 - val_accuracy: 0.9786\n",
      "Epoch 11/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.0695 - val_accuracy: 0.9777\n",
      "Epoch 12/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
      "Epoch 13/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
      "Epoch 14/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0647 - val_accuracy: 0.9801\n",
      "Epoch 15/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0653 - val_accuracy: 0.9795\n",
      "Epoch 16/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.0620 - val_accuracy: 0.9815\n",
      "Epoch 17/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0158 - accuracy: 0.9973 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
      "Epoch 18/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.0650 - val_accuracy: 0.9806\n",
      "Epoch 19/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.0639 - val_accuracy: 0.9804\n",
      "Epoch 20/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.0624 - val_accuracy: 0.9809\n",
      "Epoch 21/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0673 - val_accuracy: 0.9804\n",
      "Epoch 22/60\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.0656 - val_accuracy: 0.9812\n",
      "Epoch 23/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0642 - val_accuracy: 0.9808\n",
      "Epoch 24/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0639 - val_accuracy: 0.9812\n",
      "Epoch 25/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0648 - val_accuracy: 0.9810\n",
      "Epoch 26/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0647 - val_accuracy: 0.9813\n",
      "Epoch 27/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0648 - val_accuracy: 0.9813\n",
      "Epoch 28/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
      "Epoch 29/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0655 - val_accuracy: 0.9804\n",
      "Epoch 30/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9812\n",
      "Epoch 31/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0664 - val_accuracy: 0.9817\n",
      "Epoch 32/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 33/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9816\n",
      "Epoch 34/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9810\n",
      "Epoch 35/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9809\n",
      "Epoch 36/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9813\n",
      "Epoch 37/60\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9816\n",
      "Epoch 38/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9815\n",
      "Epoch 39/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9816\n",
      "Epoch 40/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9816\n",
      "Epoch 41/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9811\n",
      "Epoch 42/60\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 43/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 44/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9814\n",
      "Epoch 45/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9815\n",
      "Epoch 46/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9815\n",
      "Epoch 47/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9815\n",
      "Epoch 48/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9819\n",
      "Epoch 49/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9816\n",
      "Epoch 50/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9816\n",
      "Epoch 51/60\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9817\n",
      "Epoch 52/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9815\n",
      "Epoch 53/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9815\n",
      "Epoch 54/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9819\n",
      "Epoch 55/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9817\n",
      "Epoch 56/60\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 9.9502e-04 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9814\n",
      "Epoch 57/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 9.6542e-04 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9817\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 9.2665e-04 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9816\n",
      "Epoch 59/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 9.0583e-04 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9816\n",
      "Epoch 60/60\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.7579e-04 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9820\n",
      "Test loss: 0.0725211650133133, Test accuracy 0.9819999933242798\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten()) # since we want all 28x28 pixels on one row\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(300, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.L1(0.001)))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten()) # since we want all 28x28 pixels on one row\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(300, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value accuracy seems to converge at  .9816 accuracy, and the loss function seems to converge at around .726"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convolutional layers\n",
    "\n",
    "3.1. Design a model that makes use of at least one convolutional layer – how performant a\n",
    "model can you get? -- According to the MNIST database it should be possible reach to\n",
    "99% accuracy on the validation data. If you choose to use any layers apart from the\n",
    "convolutional layers and layers that you used in previous questions, you must describe\n",
    "what they do. If you do not reach 99% accuracy, report your best performance, and\n",
    "explain your attempts and thought process.\n",
    "\n",
    "3.2. Discuss the differences and potential benefits of using convolutional layers over fully\n",
    "connected ones for the application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4976 - accuracy: 0.8638 - val_loss: 0.1429 - val_accuracy: 0.9753\n",
      "Epoch 2/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.1457 - accuracy: 0.9742 - val_loss: 0.1283 - val_accuracy: 0.9801\n",
      "Epoch 3/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.1191 - accuracy: 0.9826 - val_loss: 0.1125 - val_accuracy: 0.9840\n",
      "Epoch 4/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.1057 - accuracy: 0.9868 - val_loss: 0.1088 - val_accuracy: 0.9857\n",
      "Epoch 5/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0971 - accuracy: 0.9893 - val_loss: 0.0970 - val_accuracy: 0.9890\n",
      "Epoch 6/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0906 - accuracy: 0.9911 - val_loss: 0.0988 - val_accuracy: 0.9879\n",
      "Epoch 7/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0857 - accuracy: 0.9923 - val_loss: 0.1041 - val_accuracy: 0.9865\n",
      "Epoch 8/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0796 - accuracy: 0.9942 - val_loss: 0.1019 - val_accuracy: 0.9870\n",
      "Epoch 9/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0772 - accuracy: 0.9947 - val_loss: 0.0952 - val_accuracy: 0.9897\n",
      "Epoch 10/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0739 - accuracy: 0.9955 - val_loss: 0.0886 - val_accuracy: 0.9913\n",
      "Epoch 11/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0707 - accuracy: 0.9964 - val_loss: 0.0928 - val_accuracy: 0.9901\n",
      "Epoch 12/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0677 - accuracy: 0.9971 - val_loss: 0.0925 - val_accuracy: 0.9893\n",
      "Epoch 13/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0667 - accuracy: 0.9973 - val_loss: 0.0977 - val_accuracy: 0.9877\n",
      "Epoch 14/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0656 - accuracy: 0.9975 - val_loss: 0.0925 - val_accuracy: 0.9897\n",
      "Epoch 15/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0627 - accuracy: 0.9982 - val_loss: 0.1028 - val_accuracy: 0.9869\n",
      "Epoch 16/60\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0606 - accuracy: 0.9986 - val_loss: 0.0914 - val_accuracy: 0.9905\n",
      "Epoch 17/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0602 - accuracy: 0.9988 - val_loss: 0.0932 - val_accuracy: 0.9893\n",
      "Epoch 18/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0588 - accuracy: 0.9989 - val_loss: 0.0871 - val_accuracy: 0.9911\n",
      "Epoch 19/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0576 - accuracy: 0.9990 - val_loss: 0.1186 - val_accuracy: 0.9849\n",
      "Epoch 20/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0561 - accuracy: 0.9993 - val_loss: 0.0908 - val_accuracy: 0.9902\n",
      "Epoch 21/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0547 - accuracy: 0.9997 - val_loss: 0.0866 - val_accuracy: 0.9914\n",
      "Epoch 22/60\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0545 - accuracy: 0.9994 - val_loss: 0.0876 - val_accuracy: 0.9909\n",
      "Epoch 23/60\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 0.0529 - accuracy: 0.9999"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(56, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(56, (3, 3), activation='relu'))\n",
    "model.add(Flatten()) # since we want all 28x28 pixels on one row\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(300, activation = 'relu', \n",
    "          kernel_regularizer=regularizers.L1(0.00001)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_16' (type Sequential).\n    \n    Input 0 of layer \"conv2d_2\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n    \n    Call arguments received by layer 'sequential_16' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,\n\u001b[0;32m     17\u001b[0m                optimizer\u001b[38;5;241m=\u001b[39mtensorflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     18\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],)\n\u001b[1;32m---> 20\u001b[0m fit_info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m           \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m           \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m           \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Test accuracy \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score[\u001b[38;5;241m0\u001b[39m], score[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file3yop8a_y.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\eliuh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_16' (type Sequential).\n    \n    Input 0 of layer \"conv2d_2\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n    \n    Call arguments received by layer 'sequential_16' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_7_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
