{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "Wa37fBwRF-xe"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "import random as rd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A53Gw00fBLG2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7696\r\n",
      "drwxr-xr-x    14 wushmachine  staff   448B Apr 24 10:09 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@   11 wushmachine  staff   352B Mar 27 17:37 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@    1 wushmachine  staff   6.0K Apr 24 10:09 .DS_Store\r\n",
      "drwxr-xr-x     4 wushmachine  staff   128B Apr 24 10:08 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--@    1 wushmachine  staff   1.6M Apr 24 10:06 20021010_easy_ham.tar.bz2\r\n",
      "-rw-r--r--@    1 wushmachine  staff   997K Apr 24 10:07 20021010_hard_ham.tar.bz2\r\n",
      "-rw-r--r--@    1 wushmachine  staff   1.1M Apr 24 10:07 20021010_spam.tar.bz2\r\n",
      "-rw-r--r--@    1 wushmachine  staff   589B Apr 24 10:06 Assignment4.ipynb\r\n",
      "-rw-r--r--@    1 wushmachine  staff   7.9K Apr 24 10:08 IDSAI_Assignment4_SP4_22-23.ipynb\r\n",
      "drwx--x--x@ 2553 wushmachine  staff    80K Oct 10  2002 \u001b[34measy_ham\u001b[m\u001b[m\r\n",
      "drwx--x--x@  252 wushmachine  staff   7.9K Dec 16  2004 \u001b[34mhard_ham\u001b[m\u001b[m\r\n",
      "-rw-r--r--@    1 wushmachine  staff   7.5K Apr 24 10:04 na‹ve_bayes_intro.ipynb\r\n",
      "-rw-r--r--@    1 wushmachine  staff    11K Apr 24 10:04 probability_intro.ipynb\r\n",
      "drwxr-xr-x@  503 wushmachine  staff    16K Oct 10  2002 \u001b[34mspam\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "### 1. Preprocessing: \n",
    "\n",
    "##### 1.1 Look at a few emails from easy_ham, hard_ham and spam. Do you think you would be able to classify the emails just by inspection? How do you think a succesful model can learn the difference between the different classes of emails?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2sllUWXKblD"
   },
   "outputs": [],
   "source": [
    "# Write your code for here for looking a few emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to tell the difference between easy_ham and spam, it's sometimes hard to tell the difference between hard-ham and spam, hard-ham often take the shape of poorly written newsletters, which resemble some of the strange offers embedded in spam messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text (in the optional part further down can experiment with filtering out the headers and footers). We don’t want to train and test on the same data (it might help to reflect on why if you don't recall). Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`). Use only the easy_ham part as ham data for quesions 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Write your code for here for splitting the data\n",
    "\n",
    "ham = datasets.load_files('./easy')\n",
    "#hard_ham = datasets.load_files('./hard')\n",
    "spam = datasets.load_files('./spm')\n",
    "data = datasets.load_files('./Data')\n",
    "print(SpamTrain.keys())\n",
    "print(SpamTrain.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranomizing order, might not be necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide the data into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dictionary of words from the dataset, if the target is spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3052"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coun_vect = CountVectorizer(decode_error = 'ignore')\n",
    "count_matrix = coun_vect.fit_transform(data['data'])\n",
    "count_array = count_matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names_out())\n",
    "#print(df[\"money\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split the data\n",
    "data_train, data_test, target_train, target_test = train_test_split(df, data['target'], test_size=0.3) #,random_state=109)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "#Train the model using the training sets\n",
    "gnb.fit(data_train, target_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "target_pred = gnb.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9705240174672489\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, target_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nom = MultinomialNB(force_alpha=True)\n",
    "multi_nom.fit(data_train, target_train)\n",
    "multi_nom_pred = multi_nom.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9759825327510917\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, multi_nom_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernouilli = BernoulliNB(force_alpha=True)\n",
    "bernouilli.fit(data_train, target_train)\n",
    "bernouilli_pred = bernouilli.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9061135371179039\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, bernouilli_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "### 2.1 Write a Python program that: \n",
    "1.\tUses the four datasets from Question 1 (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (use the [scikit-learn library](https://scikit-learn.org/stable/)) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. Use `CountVectorizer` ([Documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)) to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in scikit-learn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem:\n",
    "- Multinomial Naive Bayes  \n",
    "- Bernoulli Naive Bayes. \n",
    "\n",
    "Please inspect the documentation to ensure input to the classifiers is appropriate before you start coding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJERHSCcGNaW"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Answer the following questions:\n",
    "##### a) What does the CountVectorizer do?\n",
    "Answer 2.2.a\n",
    "##### b) What is the difference between Multinomial Naive Bayes and Bernoulli Naive Bayes\n",
    "Answer 2.2.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.1 Run the two models:\n",
    "Run (don't retrain) the two models from Question 2 on spam versus hard-ham. Does the performance differ compared to question 2 when the model was run on spam versus easy-ham? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gool_zb8Qzzy"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Retrain\n",
    "Retrain new Multinomial and Bernolli Naive Bayes classifers on the combined (easy+hard) ham and spam. Now evaluate on spam versus hard-ham as in 3.1. Also evaluate on spam versus easy-ham. Compare the performance with question 2 and 3.1. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Further improvements\n",
    "Do you have any suggestions for how performance could be further improved? You don't have to implement them, just present your ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.3:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
